---
title: "Machine_Learning 1"
author: "Anyoleth Alarcon (A17347293)"
format: pdf
---

## First up kmeans()

Demo of using kmeans() function in base R. First make up some data with a known structure.

```{r}
tmp <- c( rnorm(30, -3), rnorm(30, 3))
x <- cbind(x=tmp,y= rev(tmp))
plot(x)
```

Now we have some made up data in `x` let's see how kmeans works with this data

```{r}
k <- kmeans(x, centers = 2, nstart = 20)
k
```

> Q. How many points are in each cluster?

```{r}
k$size
```

> Q. How do we get to the cluster membership/assignment?

```{r}
k$cluster
```

> Q. What about cluster centers?

```{r}
k$centers
```

Now we got to the main results, let's use them to plot our data with the kmeans results.

```{r}
plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15)
```

## Now for hclust()

We will the same data `x` with the `hclust()`. In this case, `hclust()` requires a distance matrix as input.

```{r}
hc <- hclust(dist(x))
hc
```

Let's plot our hclust result

```{r}
plot(hc)
```

To get our cluster membership vector we need to "cut" the tree with the `cutree()`.

```{r}
grps <- cutree(hc, h=8)
grps
```

Now plot our data with the hclust() results.

```{r}
plot(x, col=grps)
```

# Principal Component Analysis (PCA)

## PCA of UK food data

Read data from website and try a few visualization

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names = 1)
x
```

```{r}
cols <- rainbow(nrow(x))
barplot(as.matrix(x), col=cols)
```

```{r}
barplot(as.matrix(x), col=cols, beside=TRUE)

```

```{r}
pairs(x, col=cols)
```

PCA to the rescue!!
The main base R PCA function is called `prcomp()` and we will need to give it the transpose of our input data!

```{r}
pca <- prcomp( t(x) )
```

There is a nice summary of how well PCA is doing

```{r}
summary(pca)
```

```{r}
attributes(pca)
```

To make our new PCA plot (aka PCA score plot) we access `pca$x` 

```{r}
plot(pca$x[,1], pca$x[,2])
text(pca$x[,1], pca$x[,2], colnames(x))
```

Color up the plot

```{r}
country_cols <- c("orange", "red", "blue", "green")
plot(pca$x[,1], pca$x[,2], xlab = "PC1", ylab = "PC2")
text(pca$x[,1], pca$x[,2], colnames(x), col = country_cols)
```


## PCA of RNA-Seq data

Read in data from website

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

Another PCA summary

```{r}
summary(pca)
```

```{r}
pca <- prcomp( t(rna.data))
plot(pca)
```

Do our PCA plot of this RNA-Seq data

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2",
     text(pca$x[,1], pca$x[,2], colnames(rna.data)))

```

Using ggplot to make the graph look a bit different

```{r}
library(ggplot2)

df <- as.data.frame(pca$x)

# Our first basic plot
ggplot(df) + 
  aes(PC1, PC2) + 
  geom_point()
```
Now adding some color

```{r}
# Add a 'wt' and 'ko' "condition" column
df$samples <- colnames(rna.data) 
df$condition <- substr(colnames(rna.data),1,2)

p <- ggplot(df) + 
        aes(PC1, PC2, label=samples, col=condition) + 
        geom_label(show.legend = FALSE)
p
```

Now just polishing it up...

```{r}
## Variance captured per PC 
pca.var <- pca$sdev^2

## Percent variance is often more informative to look at 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

```{r}
p + labs(title="PCA of RNASeq Data",
       subtitle = "PC1 clealy seperates wild-type from knock-out samples",
       x=paste0("PC1 (", pca.var.per[1], "%)"),
       y=paste0("PC2 (", pca.var.per[2], "%)"),
       caption="Class example data") +
     theme_bw()
```


